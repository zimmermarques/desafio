<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title type="html">How to Trace requests with RestEasy</title><link rel="alternate" href="https://www.mastertheboss.com/jboss-frameworks/resteasy/how-to-trace-requests-with-resteasy/" /><author><name>F.Marchioni</name></author><id>https://www.mastertheboss.com/jboss-frameworks/resteasy/how-to-trace-requests-with-resteasy/</id><updated>2023-04-20T11:30:45Z</updated><content type="html">When working with RESTful web services, it is often useful to be able to trace requests to better understand what is happening. Fortunately, this is relatively easy to do with WildFly and Resteasy. In this article, we will look at how to configure tracing for REST requests using an enhancement available in WildFly 28. There ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>How to build RHEL images for edge deployments</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/04/20/how-build-rhel-images-edge-deployments" /><author><name>Chris Santiago</name></author><id>26ea5a25-7501-4211-a188-9e6117aafd7e</id><updated>2023-04-20T07:00:00Z</updated><published>2023-04-20T07:00:00Z</published><summary type="html">&lt;p&gt;As &lt;a href="https://developers.redhat.com/topics/edge-computing"&gt;edge&lt;/a&gt; infrastructure scales outside the data center into remote locations, small-factor devices such as IoT, POS, and sensors that have &lt;a href="https://developers.redhat.com/topics/linux/"&gt;Linux&lt;/a&gt; images, need a way to be updated at scale.&lt;/p&gt; &lt;p&gt;The rpm-ostree core premise is that by default, the updates should base on a whole base image that is created and tested offline, and once ready deployed everywhere into the remote locations, overriding the previous image and lowering the risks of patching at scale.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_from_2023-03-03_08-55-18.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_from_2023-03-03_08-55-18.png?itok=soYJAaEV" width="533" height="354" alt="An illustration of the image builder." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: The image builder.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;We know many people are working in secure edge environments and need the ability to create and lifecycle manage operating systems. In order to help with this we have created a way to build, host and manage these images using the &lt;a href="https://developers.redhat.com/topics/ansible-automation-applications-and-services"&gt;Red Hat Ansible Automation Platform&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;This article will cover the &lt;a href="https://docs.ansible.com/ansible/latest/user_guide/collections_using.html"&gt;Ansible collection&lt;/a&gt; for management of the&lt;a href="https://www.osbuild.org/documentation/#composer"&gt; osbuild composer&lt;/a&gt; to build&lt;a href="https://rpm-ostree.readthedocs.io/en/latest/"&gt; rpm-ostree&lt;/a&gt; based images for Fedora, &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt;, and CentOS Stream. This collection has roles to build an osbuild server, an apache httpd server to host images, and a role to build installer images and rpm-ostree updates.&lt;/p&gt; &lt;h2&gt;2 roles of the infra.osbuild collection&lt;/h2&gt; &lt;p&gt;There are two roles that are part of the infra.osbuild collection:&lt;/p&gt; &lt;h3&gt;1. The infra.osbuild.setup_server role&lt;/h3&gt; &lt;p&gt;The setup_server role checks to see what type of OS the remote system is running, ostree-based or non ostree-based. A remote system running an OS based on ostree will need to have packages already installed via a previous commit or with the initial install to continue. Non-ostree based hosts will have all the necessary packages installed.&lt;/p&gt; &lt;p&gt;At the same time the setup_server role also ensures all necessary services are enabled and started. Lastly it adds support for rpm custom repositories for adding custom packages to images.&lt;/p&gt; &lt;h3&gt;2. The infra.osbuild.builder role&lt;/h3&gt; &lt;p&gt;This builder role creates a blueprint based on information provided by the playbook variables such as packages, user info, and compose type. A rpm-ostree repository is initialized for the blueprint name to handle commits and upgrades. The builder role creates an image based on the previously created blueprint. Lastly it creates a kickstart file which supports an optional auto registration to be used on a system.&lt;/p&gt; &lt;h2&gt;How to build images for edge deployment&lt;/h2&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; To test this collection you will need either a RHEL, CentOS Stream, or Fedora system.&lt;/p&gt; &lt;p&gt;Install the infra.osbuild collection using the &lt;a href="https://docs.ansible.com/ansible/latest/galaxy/user_guide.html#installing-collections"&gt;ansible-galaxy&lt;/a&gt; command as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;ansible-galaxy collection install git+https://github.com/redhat-cop/infra.osbuild&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Once installed we will make an empty directory to store the example playbooks and inventory file.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;mkdir osbuild_example&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Create an &lt;a href="https://docs.ansible.com/ansible/latest/inventory_guide/intro_inventory.html"&gt;inventory file&lt;/a&gt; as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;touch inventory.ini&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Inside the inventory file, create a group named &lt;code&gt;all&lt;/code&gt; with the remote systems IP address underneath.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-ini"&gt;[all] &lt;Host IP&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now that we have an inventory file and a remote system to point to. Let’s take a look into the setup_role. As explained above, this role simply sets up all the necessary packages and services to get osbuild up and running. If you plan on using a custom rpm repository to add custom packages that you would like to make available to osbuild then we need to add some configuration otherwise we can use the role as is.&lt;/p&gt; &lt;p&gt;Create a playbook named &lt;code&gt;osbuild_setup_server.yaml&lt;/code&gt; with the sample playbook as its contents as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-ini"&gt;--- - name: Run osbuild_server role hosts: all become: true tasks: - name: Run the role ansible.builtin.import_role: name: infra.osbuild.setup_server&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For adding a custom rpm repository, we can pass a list to the &lt;code&gt;setup_server_custom_repos&lt;/code&gt; role variable. Each list entry is a&lt;a href="https://docs.ansible.com/ansible/latest/reference_appendices/YAMLSyntax.html"&gt; YAML dictionary&lt;/a&gt; type and has the following attributes:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;&lt;code&gt;repo_name&lt;/code&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;code&gt;base_url&lt;/code&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;code&gt;type&lt;/code&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;code&gt;check_ssl&lt;/code&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;code&gt;check_gpg&lt;/code&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;code&gt;rhsm&lt;/code&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;code&gt;state&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;If you wanted support for custom rpm repositories your playbook should something like the following:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-ini"&gt;--- - name: Run osbuild_server role hosts: all become: true vars: setup_server_custom_repos: - name: EPEL Everything base_url: "https://dl.fedoraproject.org/pub/epel/{{ hostvars[inventory_hostname].ansible_distribution_major_version }}/Everything/x86_64/" type: yum-baseurl check_ssl: true check_gpg: true state: present - name: My company custom repo base_url: "https://repo.example.com/company_repo/x86_64/" type: yum-baseurl tasks: - name: Run the role ansible.builtin.import_role: name: infra.osbuild.setup_server&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now that we have the osbuild_setup_server file completed, we can run the playbook using this command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;ansible-playbook -i inventory.ini –ask-become –ask-pass playbooks/osbuild_setup_server.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; We will run the playbook with &lt;code&gt;–ask-become&lt;/code&gt; and &lt;code&gt;–ask-pass&lt;/code&gt; flags to provide basic authentication, or if you want to set up proper authentication with ssh keys and proper user sudo management.&lt;/p&gt; &lt;p&gt;Once the playbook has finished running then the osbuild server is ready for us to start building images.&lt;/p&gt; &lt;p&gt;As explained  in the infra.osbuild.builder section, there are variables that are needed to create a blueprint. You can refer to the &lt;a href="https://github.com/redhat-cop/infra.osbuild/tree/main/roles/builder"&gt;full list and their explanations&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Let’s create another playbook called &lt;code&gt;osbuild_builder.yaml&lt;/code&gt; with the sample playbook as its contents as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-ini"&gt;--- - name: Run osbuild_builder role become: true hosts: all vars: builder_compose_type: edge-commit builder_blueprint_name: mybuild builder_pub_key: ~/.ssh/id_rsa.pub builder_compose_pkgs: - vim-enhanced - httpd - ansible-core - tmux builder_compose_customizations: user: name: "testuser" description: "test user" password: "testpassword" key: "{{ builder_pub_key }}" groups: '["users", "wheel"]' tasks: - name: Run the role ansible.builtin.import_role: name: infra.osbuild.builder&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If you would like to have your image automatically register with Ansible Automation Platform, add &lt;code&gt;builder_aap_url&lt;/code&gt;, &lt;code&gt;builder_set_hostname&lt;/code&gt;, &lt;code&gt;builder_aap_ks_user&lt;/code&gt; and &lt;code&gt;builder_aap_ks_password&lt;/code&gt; underneath the vars section in the &lt;code&gt;osbuild_builder.yaml&lt;/code&gt; playbook.&lt;/p&gt; &lt;p&gt;Once you have finished writing your playbook run the &lt;code&gt;osbuild_builder.yml&lt;/code&gt; playbook to begin building an image.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;ansible-playbook -i inventory.ini –ask-become –ask-pass playbooks/osbuild_builder.yml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;After the playbook finishes, log in into your remote system &lt;code&gt;http://&lt;ip_addr&gt;/&lt;blueprint_name&gt;/&lt;/code&gt; to see the hosted repo and kickstart file that can be used to provision a new system.&lt;/p&gt; &lt;h2&gt;Find more resources&lt;/h2&gt; &lt;p&gt;In summary, infra.osbuild is an easy-to-use solution for creating customizable images. Ansible validated content for infrastructure osbuild collection, will let you automate the provisioning and configuration of the required osbuild components and build a RHEL image for your edge deployments.&lt;/p&gt; &lt;p&gt;If you want to learn more about edge &lt;a href="https://developers.redhat.com/topics/automation"&gt;automation&lt;/a&gt;, here are a few suggestions:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Explore resources at &lt;a href="https://www.ansible.com/use-cases/edge"&gt;Using Red Hat Ansible Automation Platform for edge computing&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Download the &lt;a href="https://developers.redhat.com/e-books/automation-at-the-edge"&gt;Automation at the edge e-book&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;For additional use cases such as industrial protocol integration, read the article, &lt;a href="https://developers.redhat.com/articles/2023/01/10/automate-devices-using-ansible-cip"&gt;How to automate devices using the Ansible CIP collection&lt;/a&gt;. &lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/04/20/how-build-rhel-images-edge-deployments" title="How to build RHEL images for edge deployments"&gt;How to build RHEL images for edge deployments&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Chris Santiago</dc:creator><dc:date>2023-04-20T07:00:00Z</dc:date></entry><entry><title type="html">WildFly 28 is released!</title><link rel="alternate" href="https://wildfly.org//news/2023/04/20/WildFly28-Released/" /><author><name>Brian Stansberry</name></author><id>https://wildfly.org//news/2023/04/20/WildFly28-Released/</id><updated>2023-04-20T00:00:00Z</updated><content type="html">I’m pleased to announce that the new WildFly and WildFly Preview 28.0.0.Final releases are available for download at . NEW AND NOTABLE Observability The biggest changes in WildFly 28 relate to the observability space. * The micrometer subsystem has been , bringing support. As part of this work, we’ve added support for . The micrometer subsystem was first introduced in WildFly Preview in WildFly 27. Note that the subsystem has been updated from what was in WildFly Preview 27 to switch to pushing metric data via OTLP to a remote collector, instead of supporting polling of data on the WildFly server’s management interface. (Server and JVM metrics can still be pulled from the management endpoint if the is configured.) * We’ve also added support for via a . * We’ve removed support for MicroProfile Metrics, except for a that’s been kept to facilitate configuration migration. MicroProfile Metrics users are encouraged to use the new micrometer subsystem. * We’ve removed support for MicroProfile OpenTracing, except for a that’s been kept to facilitate configuration migration. MicroProfile OpenTracing users are encouraged to use the new microprofile-telemetry subsystem, or the opentelemetry subsystem upon which it is based. MicroProfile Besides the changes in the observability space noted above, there are a couple of important changes in WildFly 28’s MicroProfile support: * We’ve for via new microprofile-lra-coordinator and microprofile-lra-participant subsystems. * Except for MicroProfile Metrics and OpenTracing, which have been removed, we’ve updated our support for the other MicroProfile Platform specifications to the versions. Because we no longer support MicroProfile Metrics, WildFly 28 cannot claim to be a compatible implementation of the MicroProfile 6.0 specification. However, WildFly’s MicroProfile support includes implementations of the following specifications in our "full" (e.g. standalone-full.xml) and "default" (e.g standalone.xml) configurations as well as our "microprofile" configurations (e.g. standalone-microprofile.xml): MicroProfile Technology WildFly Full/Default Configurations WildFly MicroProfile Configuration MicroProfile Config 3.0 X X MicroProfile Fault Tolerance 4.0  —  X MicroProfile Health 4.0  —  X MicroProfile JWT Authentication 2.1 X X MicroProfile LRA 2.0  —  X MicroProfile OpenAPI 3.1  —  X MicroProfile Open Telemetry 1.0  —  X MicroProfile Reactive Messaging 3.0  —   —  MicroProfile Reactive Streams Operators 3.0  —   —  MicroProfile Rest Client 3.0 X X Provisioning * We’ve added a new to make it easy to provision a server based on the new introduced in EE 10. * Related to this we’ve introduced new and Galleon layers. These layers allow a more tailored configuration compared to the existing ee and web-server layers. Also, separate from WildFly itself, to help users in their migration from Jakarta EE 8 to EE 10 we’ve introduced a separate that provides a new Galleon feature pack. The wildfly-deployment-transformer-feature-pack allows you to integrate into a standard WildFly installation the EE 8 to EE 9 deployment transformation functionality that we’ve since its first release. See the for documentation on how to use this new feature pack. Quickstarts * Eduardo Martins and the teams working on server provisioning and cloud have done a significant enhancement to the WildFly quickstarts to . * We’ve also added a that . Other Treats * The server kernel team has added support for . is a nice alternative to using CLI scripts to tailor a stock configuration for a particular environment, as there is no need start a CLI process to apply the customization. This makes it well suited to workflows like . * The clustering team has added support for . * The clustering and web teams have added support for . * The RESTEasy team has added support for . * The messaging-activemq subsystem now supports . * When you use OIDC, the security team has added support for . * The web team has added for Undertow listeners. * We’ve updated Hibernate ORM from the ORM 6.1 release to 6.2.1. JAKARTA EE 10 SUPPORT WildFly 28 is a compatible implementation of the EE 10 as well as the and the new . WildFly is EE 10 compatible when running on both Java SE 11 and Java SE 17. Evidence supporting our certification is available in the repository on GitHub: * Jakarta EE 10 Full Platform * * * Jakarta EE 10 Web Profile * * * Jakarta EE 10 Core Profile * * JAVA SE SUPPORT Our recommendation is that you run WildFly on the most recent long-term support Java SE release, i.e. on SE 17 for WildFly 28. While we do do some testing of WildFly on JDK 20, we do considerably more testing of WildFly itself on the LTS JDKs, and we make no attempt to ensure the projects producing the various libraries we integrate are testing their libraries on anything other than JDK 11 or 17. WildFly 28 also is heavily tested and runs well on Java 11. We plan to continue to support Java 11 at least through WildFly 29, and likely beyond. We do, however, anticipate removing support for SE 17 sometime in the next 12 to 18 months. While we recommend using an LTS JDK release, I do believe WildFly runs well on JDK 20. By runs well, I mean the main WildFly testsuite runs with no more than a few failures in areas not expected to be commonly used. We want developers who are trying to evaluate what a newer JVM means for their applications to be able to look to WildFly as a useful development platform. Please note that WildFly runs on Java 11 and later in classpath mode. KNOWN ISSUES SPRING AND RESTEASY SPRING In WildFly 27, pending the final release of Spring 6, RESTEasy Spring support was removed from standard WildFly, and was only provided with WildFly Preview. With WildFly 28 we have reintroduced RESTEasy Spring support to standard WildFly. However, we’ve learned of a in WildFly 28 that will prevent Spring deployments, including those using RESTEasy Spring, from working. Until this is resolved in WildFly 28.0.1, users can work around this issue by to their deployment that declares a dependency on the org.jboss.vfs module. RELEASE NOTES The full release notes for the release are in the . Issues fixed in the underlying and releases are listed in the WildFly Core JIRA. Please try it out and give us your feedback, while we get to work on WildFly 29! Best regards, Brian</content><dc:creator>Brian Stansberry</dc:creator></entry><entry><title>OpenJDK 8u372 to feature cgroup v2 support</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/04/19/openjdk-8u372-feature-cgroup-v2-support" /><author><name>Severin Gehwolf</name></author><id>ed0cf383-c604-47bf-b79e-5edc5248c27f</id><updated>2023-04-19T07:00:00Z</updated><published>2023-04-19T07:00:00Z</published><summary type="html">&lt;p&gt;The control group (cgroup) pseudo filesystem is the key feature enabling resource quotas on &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;containers&lt;/a&gt; deployed on &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;. The cgroups filesystem is a &lt;a href="https://developers.redhat.com/topics/linux/"&gt;Linux&lt;/a&gt; kernel feature and comes in one of three forms, depending on the hosts' configuration:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;cgroup v2, or unified hierarchy&lt;/li&gt; &lt;li&gt;cgroup v1, or legacy hierarchy&lt;/li&gt; &lt;li&gt;hybrid (basically cgroup v1, but some system services use cgroup v2).&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;The state of the art is cgroup v2. With the releases of &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift 4.12&lt;/a&gt; and &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux 9&lt;/a&gt;, which both feature cgroup v2, it becomes increasingly likely that OpenJDK 8 running in containers runs on a cgroup v2-enabled Linux kernel. Cgroup v1, the current predominant configuration, will become increasingly less frequent in practice as time moves forward.&lt;/p&gt; &lt;h2&gt;OpenJDK 8u372: cgroup v1 and v2 support&lt;/h2&gt; &lt;p&gt;With the release of OpenJDK 8u372 in April 2023, the cgroup v2 support patches present in later &lt;a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="d5069613-6b53-421b-9e45-bf8cf43625de" href="https://developers.redhat.com/articles/2022/04/19/java-17-whats-new-openjdks-container-awareness" title="Java 17: What’s new in OpenJDK's container awareness"&gt;JDK releases&lt;/a&gt; have been backported to OpenJDK 8. 30 patches in total have been backported so as to bring this feature to OpenJDK 8u. It was added to OpenJDK 8u, a very mature and stable JDK release, under the enhancement exception rule of adapting to new hardware and operating environments.&lt;/p&gt; &lt;p&gt;Version 8u372 and later will detect the cgroup version in use, v1 or v2, on the host system. Once it detects the version, it looks up the set resource limits via the pseudo filesystem hierarchy and will size its internal resources accordingly. This will ensure that OpenJDK 8 will comply to the set resource limits of containers on cgroup v2 systems, a feature OpenJDK users have grown accustomed to since it was first &lt;a href="https://bugs.openjdk.org/browse/JDK-8146115"&gt;brought to OpenJDK 8 with the 8u192&lt;/a&gt; release.&lt;/p&gt; &lt;h2&gt;How to see which cgroup version OpenJDK 8u detected&lt;/h2&gt; &lt;p&gt;One easy way to see which cgroup version, if any, OpenJDK 8u detected is by using the &lt;code&gt;-XshowSettings:system&lt;/code&gt; &lt;a href="https://developers.redhat.com/java"&gt;Java&lt;/a&gt; launcher switch. Example:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;[root@357fec96b37e /]# /opt/jdk8u372/bin/java -XshowSettings:system -version Operating System Metrics: Provider: cgroupv2 Effective CPU Count: 3 CPU Period: 100000us CPU Quota: 300000us CPU Shares: -1 List of Processors: N/A List of Effective Processors, 4 total: 0 1 2 3 List of Memory Nodes: N/A List of Available Memory Nodes, 1 total: 0 Memory Limit: 500.00M Memory Soft Limit: 0.00K Memory &amp; Swap Limit: 500.00M openjdk version "1.8.0_372-beta" OpenJDK Runtime Environment (Temurin)(build 1.8.0_372-beta-202303201451-b05) OpenJDK 64-Bit Server VM (Temurin)(build 25.372-b05, mixed mode)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Another way is to use the &lt;code&gt;-XX:+UnlockDiagnosticVMOptions -XX:+PrintContainerInfo&lt;/code&gt; JVM switches in order to see the details of which files are being looked up internally:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;[root@357fec96b37e /]# /opt/jdk8u372/bin/java -XX:+UnlockDiagnosticVMOptions -XX:+PrintContainerInfo -version OSContainer::init: Initializing Container Support Detected cgroups v2 unified hierarchy Path to /cpu.max is /sys/fs/cgroup//cpu.max Raw value for CPU quota is: 300000 CPU Quota is: 300000 Path to /cpu.max is /sys/fs/cgroup//cpu.max CPU Period is: 100000 Path to /cpu.weight is /sys/fs/cgroup//cpu.weight Raw value for CPU Shares is: 100 CPU Shares is: -1 CPU Quota count based on quota/period: 3 OSContainer::active_processor_count: 3 CgroupSubsystem::active_processor_count (cached): 3 total physical memory: 5033832448 Path to /memory.max is /sys/fs/cgroup//memory.max Raw value for memory limit is: 524288000 Memory Limit is: 524288000 total container memory: 524288000 total container memory: 524288000 CgroupSubsystem::active_processor_count (cached): 3 Path to /cpu.max is /sys/fs/cgroup//cpu.max Raw value for CPU quota is: 300000 CPU Quota is: 300000 Path to /cpu.max is /sys/fs/cgroup//cpu.max CPU Period is: 100000 Path to /cpu.weight is /sys/fs/cgroup//cpu.weight Raw value for CPU Shares is: 100 CPU Shares is: -1 CPU Quota count based on quota/period: 3 OSContainer::active_processor_count: 3 openjdk version "1.8.0_372-beta" OpenJDK Runtime Environment (Temurin)(build 1.8.0_372-beta-202303201451-b05) OpenJDK 64-Bit Server VM (Temurin)(build 25.372-b05, mixed mode)&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;OpenJDK 8u362 and older: cgroup v1 only&lt;/h2&gt; &lt;p&gt;Older releases of OpenJDK 8u will only be able to detect cgroup v1 systems. Security considerations aside, it's highly encouraged to upgrade to a later release if you are running your containers on recent cloud infrastructure such as OpenShift 4.12. For example, for a 8u362 build of OpenJDK on a cgroup's v2 system, it would look like as if the container detection failed (i.e., no metrics):&lt;/p&gt; &lt;pre&gt; &lt;code&gt;$ ./jdk8u362-b09/bin/java -XshowSettings:system -version Operating System Metrics: No metrics available for this platform openjdk version "1.8.0_362" OpenJDK Runtime Environment (Temurin)(build 1.8.0_362-b09) OpenJDK 64-Bit Server VM (Temurin)(build 25.362-b09, mixed mode) &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Onward to JDK 21&lt;/h2&gt; &lt;p&gt;While it's important to support new computing environments in older JDK releases, the next OpenJDK LTS release, OpenJDK 21, is around the corner and is scheduled to be released in September 2023. JDK 21 includes many &lt;a href="https://openjdk.org/jeps/387"&gt;more improvements&lt;/a&gt; for a better container and cloud experience. So if you are thinking of writing new Java applications, consider targeting JDK 21, and perhaps using &lt;a href="https://www.quarkus.io"&gt;Quarkus&lt;/a&gt; for the best cloud native experience!&lt;/p&gt; &lt;p&gt;Looking for more resources? &lt;a href="https://developers.redhat.com/java"&gt;Explore all things Java on Red Hat Developer.&lt;/a&gt;&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/04/19/openjdk-8u372-feature-cgroup-v2-support" title="OpenJDK 8u372 to feature cgroup v2 support"&gt;OpenJDK 8u372 to feature cgroup v2 support&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Severin Gehwolf</dc:creator><dc:date>2023-04-19T07:00:00Z</dc:date></entry><entry><title>New Features for Qute Templating Engine Support in Quarkus Tools for Visual Studio Code 1.13.0</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/vscode-quarkus-1.13.0-released/&#xA;            " /><author><name>Jessica He (https://twitter.com/JessicaJjhe)</name></author><id>https://quarkus.io/blog/vscode-quarkus-1.13.0-released/</id><updated>2023-04-19T00:00:00Z</updated><published>2023-04-19T00:00:00Z</published><summary type="html">Quarkus Tools for Visual Studio Code 1.13.0 has been released on the VS Code Marketplace and Open VSX. This release focuses on Qute Templating Engine Support by introducing support for more sections and improving template validation. New Features Notable Qute features included in Quarkus Tools for Visual Studio Code 1.13.0...</summary><dc:creator>Jessica He (https://twitter.com/JessicaJjhe)</dc:creator><dc:date>2023-04-19T00:00:00Z</dc:date></entry><entry><title type="html">Kogito 1.36.0 released!</title><link rel="alternate" href="https://blog.kie.org/2023/04/kogito-1-36-0-released.html" /><author><name>Cristiano Nicolai</name></author><id>https://blog.kie.org/2023/04/kogito-1-36-0-released.html</id><updated>2023-04-18T13:12:34Z</updated><content type="html">We are glad to announce that the Kogito 1.36.0 release is now available! This goes hand in hand with , release. From a feature point of view, we have included a series of new features and bug fixes, including: * Added support for CloudEvents to Serverless Workflow Knative custom function * Implement action condition on Serverless Workflow * Job Service embedded Quarkus extension * Added Workflow executor. This allows  embedded execution of workflows in a standard JVM.  * Added first draft of Workflow definition fluent API. This allows programmatically defining workflows.  * Added support for OnOverflow annotation. This allows users to control event publisher overflow policy through application properties.  * Fixed bug that prevents using JQ expressions in arrays.   For more details head to the complete . All artifacts are available now: * Kogito runtime artifacts are available on Maven Central. * Kogito examples can be found . * Kogito images are available on . * Kogito operator is available in the in OpenShift and Kubernetes. * Kogito tooling 0.27.0 artifacts are available at the . A detailed changelog for 1.36.0 can be found in . New to Kogito? Check out our website . Click the "Get Started" button. The post appeared first on .</content><dc:creator>Cristiano Nicolai</dc:creator></entry><entry><title>Implementing C++20 semaphores</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/04/18/implementing-c20-semaphores" /><author><name>Thomas Rodgers</name></author><id>afeb7533-a077-44a1-a7d3-be636d8d1cc2</id><updated>2023-04-18T07:00:00Z</updated><published>2023-04-18T07:00:00Z</published><summary type="html">&lt;p&gt;C++20 introduces &lt;code&gt;counting_semaphore&lt;/code&gt; and &lt;code&gt;binary_semaphore&lt;/code&gt;, which support blocking &lt;code&gt;acquire()&lt;/code&gt; and non-blocking &lt;code&gt;try_acquire()&lt;/code&gt; as well as timed &lt;code&gt;try_acquire_for()&lt;/code&gt; and &lt;code&gt;try_acquire_until()&lt;/code&gt;. On platforms that support &lt;code&gt;__platform_wait()&lt;/code&gt;/&lt;code&gt;__platform_notify()&lt;/code&gt;, we select an implementation strategy based on &lt;code&gt;atomic&lt;/code&gt;; otherwise, we attempt to use POSIX semaphores.&lt;/p&gt; &lt;p&gt;If you missed the previous article, read it here: &lt;a href="https://developers.redhat.com/articles/2022/12/06/implementing-c20-atomic-waiting-libstdc"&gt;Implementing C++20 atomic waiting in libstdc++&lt;/a&gt;&lt;/p&gt; &lt;h2&gt;Semaphores in C++&lt;/h2&gt; &lt;p&gt;Here's what the ISO C++ Standard has to say on the matter of semaphores:&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;1 Class template counting_semaphore maintains an internal counter that is initialized when the semaphore is created. The counter is decremented when a thread acquires the semaphore, and is incremented when a thread releases the semaphore. If a thread tries to acquire the semaphore when the counter is zero, the thread will block until another thread increments the counter by releasing the semaphore.&lt;/p&gt; &lt;p&gt;2 least_max_value shall be non-negative; otherwise the program is ill-formed.&lt;/p&gt; &lt;p&gt;3 Concurrent invocations of the member functions of counting_semaphore, other than its destructor, do not introduce data races.&lt;/p&gt; &lt;h4&gt;void release(ptrdiff_t update = 1);&lt;/h4&gt; &lt;p&gt;8 Preconditions: update &gt;= 0 is true, and update &lt;= max() - counter is true.&lt;/p&gt; &lt;p&gt;9 Effects: Atomically execute counter += update. Then, unblocks any threads that are waiting for counter to be greater than zero.&lt;/p&gt; &lt;p&gt;10 Synchronization: Strongly happens before invocations of try_acquire that observe the result of the effects.&lt;/p&gt; &lt;p&gt;11 Throws: system_error when an exception is required (32.2.2).&lt;/p&gt; &lt;p&gt;12 Error conditions: Any of the error conditions allowed for mutex types (32.5.4.2).&lt;/p&gt; &lt;h4&gt;bool try_acquire() noexcept;&lt;/h4&gt; &lt;p&gt;13 Effects: Attempts to atomically decrement counter if it is positive, without blocking. If counter is not decremented, there is no effect and try_acquire immediately returns. An implementation may fail to decrement counter even if it is positive. [Note 1 : This spurious failure is normally uncommon, but allows interesting implementations based on a simple compare and exchange (Clause 31). — end note] An implementation should ensure that try_acquire does not consistently return false in the absence of contending semaphore operations.&lt;/p&gt; &lt;p&gt;14 Returns: true if counter was decremented, otherwise false.&lt;/p&gt; &lt;h4&gt;void acquire();&lt;/h4&gt; &lt;p&gt;15 Effects: Repeatedly performs the following steps, in order:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;(15.1) — Evaluates try_acquire. If the result is true, returns.&lt;.li&gt;&lt;/li&gt; &lt;li&gt;(15.2) — Blocks on *this until counter is greater than zero.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;16 Throws: system_error when an exception is required (32.2.2).&lt;/p&gt; &lt;p&gt;17 Error conditions: Any of the error conditions allowed for mutex types (32.5.4.2).&lt;/p&gt; &lt;h4&gt;template bool try_acquire_for(const chrono::duration&amp; rel_time); template bool try_acquire_until(const chrono::time_point&amp; abs_time);&lt;/h4&gt; &lt;p&gt;18 Effects: Repeatedly performs the following steps, in order:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;(18.1) — Evaluates try_acquire(). If the result is true, returns true.&lt;/li&gt; &lt;li&gt;(18.2) — Blocks on *this until counter is greater than zero or until the timeout expires. If it is unblocked by the timeout expiring, returns false. The timeout expires (32.2.4) when the current time is after abs_time (for try_acquire_until) or when at least rel_time has passed from the start of the function (for try_acquire_for).&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;19 Throws: Timeout-related exceptions (32.2.4), or system_error when a non-timeout-related exception is required (32.2.2). 20 Error conditions: Any of the error conditions allowed for mutex types (32.5.4.2).&lt;/p&gt; &lt;/blockquote&gt; &lt;h2&gt;OK, so how to implement it?&lt;/h2&gt; &lt;p&gt;If we have POSIX semaphores available, the following type will be defined:&lt;/p&gt; &lt;pre&gt; struct __platform_semaphore { using __clock_t = chrono::system_clock; #ifdef SEM_VALUE_MAX static constexpr ptrdiff_t _S_max = SEM_VALUE_MAX; #else static constexpr ptrdiff_t _S_max = _POSIX_SEM_VALUE_MAX; #endif explicit __platform_semaphore(ptrdiff_t __count) noexcept { sem_init(&amp;_M_semaphore, 0, __count); } ~__platform_semaphore() { sem_destroy(&amp;_M_semaphore); } // ... }; &lt;/pre&gt; &lt;p&gt;And implements &lt;code&gt;acquire&lt;/code&gt;/​​​​​​&lt;code&gt;try_acquire&lt;/code&gt;/&lt;code&gt;release&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; struct __platform_semaphore { // ... void _M_acquire() noexcept { for (;;) { auto __err = sem_wait(&amp;_M_semaphore); if (__err &amp;&amp; (errno == EINTR)) continue; else if (__err) std::terminate(); else break; } } _GLIBCXX_ALWAYS_INLINE bool _M_try_acquire() noexcept { for (;;) { auto __err = sem_trywait(&amp;_M_semaphore); if (__err &amp;&amp; (errno == EINTR)) continue; else if (__err &amp;&amp; (errno == EAGAIN)) return false; else if (__err) std::terminate(); else break; } return true; } _GLIBCXX_ALWAYS_INLINE void _M_release(std::ptrdiff_t __update) noexcept { for(; __update != 0; --__update) { auto __err = sem_post(&amp;_M_semaphore); if (__err) std::terminate(); } } // ... }; &lt;/pre&gt; &lt;p&gt;For the timed wait operations, we have to worry about what the "basis" clock is and how to convert the user-supplied clock. For POSIX semaphores, this is handled as follows:&lt;/p&gt; &lt;pre&gt; struct __platform_semaphore { using __clock_t = chrono::system_clock; // ... bool _M_try_acquire_until_impl(const chrono::time_point&lt;__clock_t&gt;&amp; __atime) noexcept { auto __s = chrono::time_point_cast(__atime); auto __ns = chrono::duration_cast(__atime - __s); struct timespec __ts = { static_cast(__s.time_since_epoch().count()), static_cast(__ns.count()) }; for (;;) { if (auto __err = sem_timedwait(&amp;_M_semaphore, &amp;__ts)) { if (errno == EINTR) continue; else if (errno == ETIMEDOUT || errno == EINVAL) return false; else std::terminate(); } else break; } return true; } template bool _M_try_acquire_until(const chrono::time_point&lt;_Clock, _Duration&gt;&amp; __atime) noexcept { if constexpr (std::is_same_v&lt;__clock_t, _Clock&gt;) { return _M_try_acquire_until_impl(__atime); } else { const typename _Clock::time_point __c_entry = _Clock::now(); const auto __s_entry = __clock_t::now(); const auto __delta = __atime - __c_entry; const auto __s_atime = __s_entry + __delta; if (_M_try_acquire_until_impl(__s_atime)) return true; // We got a timeout when measured against __clock_t but // we need to check against the caller-supplied clock // to tell whether we should return a timeout. return (_Clock::now() &lt; __atime); } } }; &lt;/pre&gt; &lt;p&gt;If we have support for &lt;code&gt;atomic::wait&lt;/code&gt;/&lt;code&gt;notify_one&lt;/code&gt;/&lt;code&gt;all&lt;/code&gt; then the following type will be defined:&lt;/p&gt; &lt;pre&gt; struct __atomic_semaphore { static constexpr ptrdiff_t _S_max = __gnu_cxx::__int_traits::__max; explicit __atomic_semaphore(__detail::__platform_wait_t __count) noexcept : _M_counter(__count) { __glibcxx_assert(__count &gt;= 0 &amp;&amp; __count &lt;= _S_max); } static _GLIBCXX_ALWAYS_INLINE bool _S_do_try_acquire(__detail::__platform_wait_t* __counter) noexcept { auto __old = __atomic_impl::load(__counter, memory_order::acquire); if (__old == 0) return false; return __atomic_impl::compare_exchange_strong(__counter, __old, __old - 1, memory_order::acquire, memory_order::relaxed); } _GLIBCXX_ALWAYS_INLINE void _M_acquire() noexcept { auto const __pred = [this] {return _S_do_try_acquire(&amp;this-&gt;_M_counter);}; std::__atomic_wait_address(&amp;_M_counter, __pred); } bool _M_try_acquire() noexcept { auto const __pred = [this] { return _S_do_try_acquire(&amp;this-&gt;_M_counter); }; return std::__detail::__atomic_spin(__pred); } // ... }; &lt;/pre&gt; &lt;p&gt;This expects an implementation of &lt;code&gt;__atomic_wait_address&lt;/code&gt; that can accept a predicate; however, we have only defined &lt;code&gt;__atomic_wait_address_v&lt;/code&gt; to this point (see &lt;a href="https://developers.redhat.com/articles/2022/12/06/implementing-c20-atomic-waiting-libstdc"&gt;part 1&lt;/a&gt;).&lt;/p&gt; &lt;pre&gt; template&lt;typename _EntersWait&gt; struct __waiter { // ... template&lt;typename _Pred&gt; void _M_do_wait(_Pred __pred) noexcept { do { __platform_wait_t __val; if (__base_type::_M_do_spin(__pred, __val)) return; __base_type::_M_w._M_do_wait(__base_type::_M_addr, __val); } while (!__pred()); } }; template&lt;typename _Tp, typename _Pred&gt; void __atomic_wait_address(const _Tp* __addr, _Pred __pred) noexcept { __detail::__enters_wait __w(__addr); __w._M_do_wait(__pred); } &lt;/pre&gt; &lt;p&gt;There is a problem with this formulation, in that &lt;code&gt;__enters_wait&lt;/code&gt; will atomically increment and decrement a waiter count, which &lt;code&gt;__atomic_semaphore&lt;/code&gt; does not need, as it inherently tracks the presence of waiters. In the previous article, we introduced the notion of &lt;code&gt;__enters_wait&lt;/code&gt; and &lt;code&gt;__bare_wait&lt;/code&gt; types to be used by waiters and notifiers, respectively. We extend that notion also to support "bare" waiters.&lt;/p&gt; &lt;pre&gt; // This call is to be used by atomic types which track contention externally template void __atomic_wait_address_bare(const __detail::__platform_wait_t* __addr, _Pred __pred) noexcept { #ifdef _GLIBCXX_HAVE_PLATFORM_WAIT do { __detail::__platform_wait_t __val; if (__detail::__bare_wait::_S_do_spin(__addr, __pred, __val)) return; __detail::__platform_wait(__addr, __val); } while (!__pred()); #else // !_GLIBCXX_HAVE_PLATFORM_WAIT __detail::__bare_wait __w(__addr); __w._M_do_wait(__pred); #endif } &lt;/pre&gt; &lt;p&gt;We also need to introduce a corresponding "bare" &lt;code&gt;notify&lt;/code&gt;, which skips checks for waiters:&lt;/p&gt; &lt;pre&gt; struct __waiter_pool { // ... void _M_notify(const __platform_wait_t* __addr, bool __all, bool __bare) noexcept { if (!(__bare || _M_waiting())) return; #ifdef _GLIBCXX_HAVE_PLATFORM_WAIT __platform_notify(__addr, __all); #else if (__all) _M_cv.notify_all(); else _M_cv.notify_one(); #endif } }; &lt;/pre&gt; &lt;h3&gt;Supporting timed waits on __atomic_semaphore&lt;/h3&gt; &lt;p&gt;The C++ Standard has extensive support for durations and time points and specifies waiting operations in terms of those types:&lt;/p&gt; &lt;pre&gt; template&lt;class Rep, class Period&gt; bool try_acquire_for(const chrono::duration&lt;Rep, Period&gt;&amp; rel_time); template&lt;class Clock, class Duration&gt; bool try_acquire_until(const chrono::time_point&lt;Clock, Duration&gt;&amp; abs_time); &lt;/pre&gt; &lt;p&gt;However, &lt;code&gt;&lt;chrono&gt;&lt;/code&gt; is not supported in the freestanding (non-hosted) subset of the standard library, but &lt;code&gt;&lt;atomic&gt;&lt;/code&gt; is. This means we can't inject a dependency on the header or in its underlying &lt;code&gt;bits/atomic_base.h&lt;/code&gt; header. For this reason, all timed waiting functionality is split to &lt;code&gt;bits/atomic_timed_wait.h&lt;/code&gt;. We preferentially use &lt;code&gt;std::chrono::steady_clock&lt;/code&gt; as our basis clock on platforms that have futexes or &lt;code&gt;pthread_cond_clockwait&lt;/code&gt;. Otherwise, we fall back to the &lt;code&gt;system_clock&lt;/code&gt; and convert all user-supplied time points to this clock:&lt;/p&gt; &lt;pre&gt; #ifdef _GLIBCXX_HAVE_LINUX_FUTEX || _GLIBCXX_USE_PTHREAD_COND_CLOCKWAIT using __wait_clock_t = chrono::steady_clock; #else using __wait_clock_t = chrono::system_clock; #endif template&lt;typename _Clock, typename _Dur&gt; __wait_clock_t::time_point __to_wait_clock(const chrono::time_point&lt;_Clock, _Dur&gt;&amp; __atime) noexcept { const typename _Clock::time_point __c_entry = _Clock::now(); const __wait_clock_t::time_point __w_entry = __wait_clock_t::now(); const auto __delta = __atime - __c_entry; using __w_dur = typename __wait_clock_t::duration; return __w_entry + chrono::ceil&lt;__w_dur&gt;(__delta); } template&lt;typename _Dur&gt; __wait_clock_t::time_point __to_wait_clock(const chrono::time_point&lt;__wait_clock_t, _Dur&gt;&amp; __atime) noexcept { using __w_dur = typename __wait_clock_t::duration; return chrono::ceil&lt;__w_dur&gt;(__atime); } &lt;/pre&gt; &lt;p&gt;If a platform supports an efficient &lt;code&gt;__platform_wait()&lt;/code&gt;, it is also expected to provide an efficient timed wait version of the same called &lt;code&gt;__platform_wait_until()&lt;/code&gt;. For Linux Futexes, we implement this as:&lt;/p&gt; &lt;pre&gt; // returns true if wait ended before timeout template&lt;typename _Dur&gt; bool __platform_wait_until_impl(const __platform_wait_t* __addr, __platform_wait_t __old, const chrono::time_point&lt;__wait_clock_t, _Dur&gt;&amp; __atime) noexcept { auto __s = chrono::time_point_cast&lt;chrono::seconds&gt;(__atime); auto __ns = chrono::duration_cast&lt;chrono::nanoseconds&gt;(__atime - __s); struct timespec __rt = { static_cast&lt;std::time_t&gt;(__s.time_since_epoch().count()), static_cast&lt;long&gt;(__ns.count()) }; auto __e = syscall (SYS_futex, __addr, static_cast&lt;int&gt;(__futex_wait_flags::__wait_bitset_private), __old, &amp;__rt, nullptr, static_cast&lt;int&gt;(__futex_wait_flags:: __bitset_match_any)); if (__e) { if ((errno != ETIMEDOUT) &amp;&amp; (errno != EINTR) &amp;&amp; (errno != EAGAIN)) __throw_system_error(errno); return true; } return false; } // returns true if wait ended before timeout template&lt;typename _Clock, typename _Dur&gt; bool __platform_wait_until(const __platform_wait_t* __addr, __platform_wait_t __old, const chrono::time_point&lt;_Clock, _Dur&gt;&amp; __atime) { if constexpr (is_same_v&lt;__wait_clock_t, _Clock&gt;) { return __platform_wait_until_impl(__addr, __old, __atime); } else { if (!__platform_wait_until_impl(__addr, __old, __to_wait_clock(__atime))) { // We got a timeout when measured against __clock_t but // we need to check against the caller-supplied clock // to tell whether we should return a timeout. if (_Clock::now() &lt; __atime) return true; } return false; } } &lt;/pre&gt; &lt;p&gt;As with &lt;code&gt;__platform_wait()&lt;/code&gt;, for platforms that do not provide &lt;code&gt;__platform_wait_until()&lt;/code&gt;, we fall back to using a mutex and condition variable and defining the following support functions:&lt;/p&gt; &lt;pre&gt; // Returns true if wait ended before timeout. // _Clock must be either steady_clock or system_clock. template&lt;typename _Clock, typename _Dur&gt; bool __cond_wait_until_impl(__condvar&amp; __cv, mutex&amp; __mx, const chrono::time_point&lt;_Clock, _Dur&gt;&amp; __atime) { static_assert(std::__is_one_of&lt;_Clock, chrono::steady_clock, chrono::system_clock&gt;::value); auto __s = chrono::time_point_cast&lt;chrono::seconds&gt;(__atime); auto __ns = chrono::duration_cast&lt;chrono::nanoseconds&gt;(__atime - __s); __gthread_time_t __ts = { static_cast&lt;std::time_t&gt;(__s.time_since_epoch().count()), static_cast&lt;long&lt;(__ns.count()) }; // if we have a pthreads implementation that supports CLOCK_MONOTONIC // and the caller's clock is steady_clock, use that #ifdef _GLIBCXX_USE_PTHREAD_COND_CLOCKWAIT if constexpr (is_same_v&lt;chrono::steady_clock, _Clock&gt;) __cv.wait_until(__mx, CLOCK_MONOTONIC, __ts); else #endif __cv.wait_until(__mx, __ts); return _Clock::now() &amp; __atime; } // returns true if wait ended before timeout template&lt;typename _Clock, typename _Dur&gt; bool __cond_wait_until(__condvar&amp; __cv, mutex&amp; __mx, const chrono::time_point&lt;_Clock, _Dur&gt;&amp; __atime) { #ifdef _GLIBCXX_USE_PTHREAD_COND_CLOCKWAIT if constexpr (is_same_v&lt;_Clock, chrono::steady_clock&gt;) return __detail::__cond_wait_until_impl(__cv, __mx, __atime); else #endif if constexpr (is_same_v&lt;_Clock, chrono::system_clock&gt;) return __detail::__cond_wait_until_impl(__cv, __mx, __atime); else { if (__cond_wait_until_impl(__cv, __mx, __to_wait_clock(__atime))) { // We got a timeout when measured against __clock_t but // we need to check against the caller-supplied clock // to tell whether we should return a timeout. if (_Clock::now() &lt; __atime) return true; } return false; } } &lt;/pre&gt; &lt;p&gt;The formulation of &lt;code&gt;__waiter_pool&lt;/code&gt; from &lt;a href="https://developers.redhat.com/articles/2022/12/06/implementing-c20-atomic-waiting-libstdc"&gt;part 1&lt;/a&gt; assumes that we are in the market for indefinitely blocking waits. However, in this case, we only care about timed waiting. The actual implementation in &lt;code&gt;bits/atomic_wait.h&lt;/code&gt; is:&lt;/p&gt; &lt;pre&gt; struct __waiter_pool_base { // ... alignas(_S_align) __platform_wait_t _M_wait = 0; #ifndef _GLIBCXX_HAVE_PLATFORM_WAIT mutex _M_mtx; #endif alignas(_S_align) __platform_wait_t _M_ver = 0; #ifndef _GLIBCXX_HAVE_PLATFORM_WAIT __condvar _M_cv; #endif void _M_enter_wait() noexcept; void _M_leave_wait() noexcept; bool _M_waiting() const noexcept; void _M_notify(const __platform_wait_t* __addr, bool __all, bool __bare) noexcept; static __waiter_pool_base&amp; _S_for(const void* __addr) noexcept; }; &lt;/pre&gt; &lt;p&gt;For indefinite atomic waits, the derived type &lt;code&gt;__waiter_pool&lt;/code&gt; is used:&lt;/p&gt; &lt;pre&gt; struct __waiter_pool : __waiter_pool_base { void _M_do_wait(const __platform_wait_t* __addr, __platform_wait_t __old) noexcept; }; &lt;/pre&gt; &lt;p&gt;For timed atomic waits, the derived type &lt;code&gt;__timed_waiter_pool&lt;/code&gt; is used:&lt;/p&gt; &lt;pre&gt; struct __timed_waiter_pool : __waiter_pool_base { // returns true if wait ended before timeout template bool _M_do_wait_until(__platform_wait_t* __addr, __platform_wait_t __old, const chrono::time_point&lt;_Clock, _Dur&gt;&amp; __atime) { #ifdef _GLIBCXX_HAVE_PLATFORM_TIMED_WAIT return __platform_wait_until(__addr, __old, __atime); #else __platform_wait_t __val; __atomic_load(__addr, &amp;__val, __ATOMIC_RELAXED); if (__val == __old) { lock_guard __l(_M_mtx); return __cond_wait_until(_M_cv, _M_mtx, __atime); } #endif // _GLIBCXX_HAVE_PLATFORM_TIMED_WAIT } }; &lt;/pre&gt; &lt;p&gt;Similarly, &lt;code&gt;__waiter&lt;/code&gt; is split into a &lt;code&gt;__waiter_base&lt;/code&gt; type:&lt;/p&gt; &lt;pre&gt; template&lt;typename _Tp&gt; struct __waiter_base { using __waiter_type = _Tp; __waiter_type&amp; _M_w; __platform_wait_t* _M_addr; template static __platform_wait_t* _S_wait_addr(const _Up* __a, __platform_wait_t* __b); static __waiter_type&amp; _S_for(const void* __addr) noexcept { static_assert(sizeof(__waiter_type) == sizeof(__waiter_pool_base)); auto&amp; res = __waiter_pool_base::_S_for(__addr); return reinterpret_cast&lt;__waiter_type&amp;&gt;(res); } template&lt;typename _Up&gt; explicit __waiter_base(const _Up* __addr) noexcept : _M_w(_S_for(__addr)) , _M_addr(_S_wait_addr(__addr, &amp;_M_w._M_ver)) { } void _M_notify(bool __all, bool __bare = false); template&lt;typename _Up, typename _ValFn, typename _Spin = __default_spin_policy&gt; static bool _S_do_spin_v(__platform_wait_t* __addr, const _Up&amp; __old, _ValFn __vfn, __platform_wait_t&amp; __val, _Spin __spin = _Spin{ }); template&lt;typename _Up, typename _ValFn, typename _Spin = __default_spin_policy&gt; bool _M_do_spin_v(const _Up&amp; __old, _ValFn __vfn, __platform_wait_t&amp; __val, _Spin __spin = _Spin{ }); template&lt;typename _Pred, typename _Spin = __default_spin_policy&gt; static bool _S_do_spin(const __platform_wait_t* __addr, _Pred __pred, __platform_wait_t&amp; __val, _Spin __spin = _Spin{ }); template&lt;typename _Pred, typename _Spin = __default_spin_policy&gt; bool _M_do_spin(_Pred __pred, __platform_wait_t&amp; __val, _Spin __spin = _Spin{ }); }; &lt;/pre&gt; &lt;p&gt;From which &lt;code&gt;__waiter&lt;/code&gt; is derived:&lt;/p&gt; &lt;pre&gt; template&lt;typename _EntersWait&gt; struct __waiter : __waiter_base&lt;__waiter_pool&gt; { using __base_type = __waiter_base&lt;__waiter_pool&gt;; template&lt;typename _Tp&gt; __waiter(const _Tp* __addr) noexcept; // ... template&lt;typename _Tp, typename _ValFn&gt; void _M_do_wait_v(_Tp __old, _ValFn __vfn); template&lt;typename _Pred&gt; void _M_do_wait(_Pred __pred) noexcept; }; using __enters_wait = __waiter&lt;std::true_type&gt;; using __bare_wait = __waiter&lt;std::false_type&gt;; &lt;/pre&gt; &lt;p&gt;&lt;code&gt;__timed_waiter&lt;/code&gt; is similarly derived:&lt;/p&gt; &lt;pre&gt; template&lt;typename _EntersWait&gt; struct __timed_waiter : __waiter_base&lt;__timed_waiter_pool&gt; { using __base_type = __waiter_base&lt;__timed_waiter_pool&gt;; template&lt;typename _Tp&gt; __timed_waiter(const _Tp* __addr) noexcept; // ... // returns true if wait ended before timeout template&lt;typename _Tp, typename _ValFn, typename _Clock, typename _Dur&gt; bool _M_do_wait_until_v(_Tp __old, _ValFn __vfn, const chrono::time_point&lt;_Clock, _Dur&gt;&amp; __atime) noexcept; // returns true if wait ended before timeout template&lt;typename _Pred, typename _Clock, typename _Dur&gt; bool _M_do_wait_until(_Pred __pred, __platform_wait_t __val, const chrono::time_point&lt;_Clock, _Dur&gt;&amp; __atime) noexcept; // returns true if wait ended before timeout template&lt;typename _Pred, typename _Clock, typename _Dur&gt; bool _M_do_wait_until(_Pred __pred, const chrono::time_point&lt;_Clock, _Dur&gt;&amp; __atime) noexcept; template&lt;typename _Tp, typename _ValFn, typename _Rep, typename _Period&gt; bool _M_do_wait_for_v(_Tp __old, _ValFn __vfn, const chrono::duration&lt;_Rep, _Period&gt;&amp; __rtime) noexcept; template&lt;typename _Pred, typename _Rep, typename _Period&gt; bool _M_do_wait_for(_Pred __pred, const chrono::duration&lt;_Rep, _Period&gt;&amp; __rtime) noexcept; }; using __enters_timed_wait = __timed_waiter&lt;std::true_type&gt;; using __bare_timed_wait = __timed_waiter&lt;std::false_type&gt;; &lt;/pre&gt; &lt;p&gt;As with &lt;code&gt;__waiter&lt;/code&gt;, there are top-level &lt;code&gt;__atomic_wait_address_until&lt;/code&gt;/&lt;code&gt;for&lt;/code&gt; wrappers that &lt;code&gt;__atomic_semaphore&lt;/code&gt; calls into, all of which follow the general form of:&lt;/p&gt; &lt;pre&gt; // returns true if wait ended before timeout template&lt;typename _Tp, typename _ValFn, typename _Clock, typename _Dur&gt; bool __atomic_wait_address_until_v(const _Tp* __addr, _Tp&amp;&amp; __old, _ValFn&amp;&amp; __vfn, const chrono::time_point&lt;_Clock, _Dur&gt;&amp; __atime) noexcept { __detail::__enters_timed_wait __w{__addr}; return __w._M_do_wait_until_v(__old, __vfn, __atime); } template&lt;typename _Tp, typename _Pred, typename _Clock, typename _Dur&gt; bool __atomic_wait_address_until(const _Tp* __addr, _Pred __pred, const chrono::time_point&lt;_Clock, _Dur&gt;&amp; __atime) noexcept { __detail::__enters_timed_wait __w{__addr}; return __w._M_do_wait_until(__pred, __atime); } &lt;/pre&gt; &lt;p&gt;With versions for "bare" wait and the &lt;code&gt;_for_v/_&lt;/code&gt;for variants to wait for a supplied duration. The actual waiting entry points on &lt;code&gt;__timed_waiter&lt;/code&gt; are implemented as follows:&lt;/p&gt; &lt;pre&gt; struct __timed_waiter { // ... template&lt;typename _Tp, typename _ValFn, typename _Clock, typename _Dur&gt; bool _M_do_wait_until_v(_Tp __old, _ValFn __vfn, const chrono::time_point&lt;_Clock, _Dur&gt;&amp; __atime) noexcept { __platform_wait_t __val; if (_M_do_spin(__old, std::move(__vfn), __val, __timed_backoff_spin_policy(__atime))) return true; return __base_type::_M_w._M_do_wait_until(__base_type::_M_addr, __val, __atime); } template&lt;typename _Pred, typename _Clock, typename _Dur&gt; bool _M_do_wait_until(_Pred __pred, __platform_wait_t __val, const chrono::time_point&lt;_Clock, _Dur&gt;&amp; __atime) noexcept { for (auto __now = _Clock::now(); __now &lt; __atime; __now = _Clock::now()) { if (__base_type::_M_do_spin(__pred, __val, __timed_backoff_spin_policy(__atime, __now))) return true; if (__base_type::_M_w._M_do_wait_until(__base_type::_M_addr, __val, __atime) &amp;&amp; __pred()) return true; } return false; } }; &lt;/pre&gt; &lt;p&gt;Aside from the usual differences between the &lt;code&gt;_v&lt;/code&gt; and predicate forms of wait, the timed waits introduce a custom spin policy:&lt;/p&gt; &lt;pre&gt; struct __timed_backoff_spin_policy { __wait_clock_t::time_point _M_deadline; __wait_clock_t::time_point _M_t0; template&lt;typename _Clock, typename _Dur&gt; __timed_backoff_spin_policy(chrono::time_point&lt;_Clock, _Dur&gt; __deadline = _Clock::time_point::max(), chrono::time_point&lt;_Clock, _Dur&gt; __t0 = _Clock::now()) noexcept : _M_deadline(__to_wait_clock(__deadline)) , _M_t0(__to_wait_clock(__t0)) { } bool operator()() const noexcept { using namespace literals::chrono_literals; auto __now = __wait_clock_t::now(); if (_M_deadline &lt;= __now) return false; auto __elapsed = __now - _M_t0; if (__elapsed &gt; 128ms) { this_thread::sleep_for(64ms); } else if (__elapsed &gt; 64us) { this_thread::sleep_for(__elapsed / 2); } else if (__elapsed &gt; 4us) { __thread_yield(); } else return false; return true; } }; &lt;/pre&gt; &lt;p&gt;After the usual spin completes unsatisfied, this will begin sleeping the current thread as long as the deadline hasn't been reached. The relative &lt;code&gt;wait_for&lt;/code&gt; variants are implemented in terms of the absolute &lt;code&gt;wait_until&lt;/code&gt; members:&lt;/p&gt; &lt;pre&gt; struct __timed_waiter { // ... template&lt;typename _Tp, typename _ValFn, typename _Rep, typename _Period&gt; bool _M_do_wait_for_v(_Tp __old, _ValFn __vfn, const chrono::duration&lt;_Rep, _Period&gt;&amp; __rtime) noexcept { __platform_wait_t __val; if (_M_do_spin_v(__old, std::move(__vfn), __val)) return true; if (!__rtime.count()) return false; // no rtime supplied, and spin did not acquire auto __reltime = chrono::ceil&lt;__wait_clock_t::duration&gt;(__rtime); return __base_type::_M_w._M_do_wait_until(_base_type::_M_addr, __val, chrono::steady_clock::now() + __reltime); } template&lt;typename _Pred, typename _Rep, typename _Period&gt; bool _M_do_wait_for(_Pred __pred, const chrono::duration&lt;_Rep, _Period&gt;&amp; __rtime) noexcept { __platform_wait_t __val; if (__base_type::_M_do_spin(__pred, __val)) return true; if (!__rtime.count()) return false; // no rtime supplied, and spin did not acquire auto __reltime = chrono::ceil&lt;__wait_clock_t::duration&gt;(__rtime); return _M_do_wait_until(__pred, __val, chrono::steady_clock::now() + __reltime); } }; &lt;/pre&gt; &lt;h3&gt;The rest of __atomic_semaphore&lt;/h3&gt; &lt;p&gt;With support for atomic timed waits in place, we can define the remaining members of &lt;code&gt;__atomic_semaphore&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; struct __atomic_semaphore { // ... template&lt;typename _Clock, typename _Duration&gt; _GLIBCXX_ALWAYS_INLINE bool _M_try_acquire_until(const chrono::time_point&lt;_Clock, _Duration&gt;&amp; __atime) noexcept { auto const __pred = [this] { return _S_do_try_acquire(&amp;this-&gt;_M_counter); }; return __atomic_wait_address_until_bare(&amp;_M_counter, __pred, __atime); } template&lt;typename _Rep, typename _Period&gt; _GLIBCXX_ALWAYS_INLINE bool _M_try_acquire_for(const chrono::duration&lt;_Rep, _Period&gt;&amp; __rtime) noexcept { auto const __pred = [this] { return _S_do_try_acquire(&amp;this-&gt;_M_counter); }; return __atomic_wait_address_for_bare(&amp;_M_counter, __pred, __rtime); } }; &lt;/pre&gt; &lt;p&gt;You might have observed that there are more &lt;code&gt;__atomic_wait_address_for&lt;/code&gt;/&lt;code&gt;until&lt;/code&gt; variations than are actually used by &lt;code&gt;__atomic_semaphore&lt;/code&gt;. C++26 will likely add timed versions of &lt;code&gt;wait()&lt;/code&gt; to &lt;code&gt;atomic&lt;/code&gt; as well as a version that accepts a predicate. The underlying support for these operations is already present but not yet exposed via the interface of &lt;code&gt;atomic,&lt;/code&gt; and the details are subject to change in a future version of GCC.&lt;/p&gt; &lt;h3&gt;The rest of &lt;semaphore&gt;&lt;/h3&gt; &lt;p&gt;The semaphore implementation to use is conditionally chosen based on the presence of the atomic wait feature-test macro:&lt;/p&gt; &lt;pre&gt; #if defined __cpp_lib_atomic_wait using __semaphore_impl = __atomic_semaphore; #elif _GLIBCXX_HAVE_POSIX_SEMAPHORE using __semaphore_impl = __platform_semaphore; #endif &lt;/pre&gt; &lt;p&gt;We then implement s&lt;code&gt;td::counting_semaphore&lt;/code&gt; in terms of &lt;code&gt;__semaphore_impl&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; template&lt;ptrdiff_t __least_max_value = __semaphore_impl::_S_max&gt; class counting_semaphore { static_assert(__least_max_value &gt;= 0); static_assert(__least_max_value &lt;= __semaphore_impl::_S_max); __semaphore_impl _M_sem; public: explicit counting_semaphore(ptrdiff_t __desired) noexcept : _M_sem(__desired) { } ~counting_semaphore() = default; counting_semaphore(const counting_semaphore&amp;) = delete; counting_semaphore&amp; operator=(const counting_semaphore&amp;) = delete; static constexpr ptrdiff_t max() noexcept { return __least_max_value; } void release(ptrdiff_t __update = 1) noexcept(noexcept(_M_sem._M_release(1))) { _M_sem._M_release(__update); } void acquire() noexcept(noexcept(_M_sem._M_acquire())) { _M_sem._M_acquire(); } bool try_acquire() noexcept(noexcept(_M_sem._M_try_acquire())) { return _M_sem._M_try_acquire(); } template&lt;typename _Rep, typename _Period&gt; bool try_acquire_for(const std::chrono::duration&lt;_Rep, _Period&gt;&amp; __rtime) { return _M_sem._M_try_acquire_for(__rtime); } template&lt;typename _Clock, typename _Dur&gt; bool try_acquire_until(const std::chrono::time_point&lt;_Clock, _Dur&gt;&amp; __atime) { return _M_sem._M_try_acquire_until(__atime); } }; &lt;/pre&gt; &lt;p&gt;And &lt;code&gt;std::binary_semaphore&lt;/code&gt; is just a type alias:&lt;/p&gt; &lt;pre&gt; using binary_semaphore = std::counting_semaphore&lt;1&gt;; &lt;/pre&gt; &lt;h2&gt;Next time&lt;/h2&gt; &lt;p&gt;With all of the waiting detail and semaphores out of the way, the next installment will look at &lt;code&gt;&lt;latch&gt;&lt;/code&gt; and &lt;code&gt;&lt;barrier&gt;&lt;/code&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/04/18/implementing-c20-semaphores" title="Implementing C++20 semaphores"&gt;Implementing C++20 semaphores&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Thomas Rodgers</dc:creator><dc:date>2023-04-18T07:00:00Z</dc:date></entry><entry><title>My advice for transitioning to a clean architecture platform</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/04/17/my-advice-transitioning-clean-architecture-platform" /><author><name>Maarten Vandeperre, Kevin Dubois</name></author><id>ddcab0d1-0a01-4520-9b72-a081a2a66062</id><updated>2023-04-17T07:01:00Z</updated><published>2023-04-17T07:01:00Z</published><summary type="html">&lt;p&gt;Now that you have become an application development expert, it’s time to look at how clean architecture would look when we map it to the infrastructure side of an &lt;a href="https://developers.redhat.com/app-dev-platform"&gt;application platform&lt;/a&gt;. In case you're not familiar with clean architecture, read part one in this series, &lt;a href="https://developers.redhat.com/articles/2023/04/17/my-advice-building-maintainable-clean-architecture"&gt;My advice for building maintainable, clean architecture&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Preferred application platform architecture&lt;/h2&gt; &lt;p&gt;Before we get into the clean architecture mapping of our application platform, let’s describe how it should look (Figure 1).&lt;/p&gt; &lt;p&gt;We will have these four &lt;a href="https://developers.redhat.com/topics/microservices/"&gt;microservices&lt;/a&gt;:&lt;/p&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;&lt;strong&gt;Personal data service&lt;/strong&gt;: Capturing personal information (i.e., email, name, phone number, age, gender, and address). Since this kind of data is relational in nature, we would opt for a relational database for this service.&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Movies catalog service&lt;/strong&gt;: A service to capture all movies from which we have collected data (i.e., name, director, actors, release date, and categories). We prefer to have this data stored in a NoSQL database.&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Movie tracking service&lt;/strong&gt;: A service to store tracking information about who watched a movie. Data is very limited (i.e., person ID, movie ID, timestamp, and if the movie was completed). We prefer to have this data stored in a NoSQL database.&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Movie recommendation service&lt;/strong&gt;: A service that consumes data from the previous three microservices to provide recommendations based on viewer habits, age, gender, and broad location). Since this is connected data, we prefer to have this data stored in a graph database. Here too, we let go of DRY - data copied to the graph.&lt;/li&gt; &lt;/ol&gt;&lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/step_1_service_outline.jpeg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/step_1_service_outline.jpeg?itok=xwmBanec" width="600" height="236" alt="An illustration of the microservices outline of preferred platform architecture" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;span class="field field--name-field-creator field--type-string field--label-inline field__items"&gt; &lt;span class="field__label"&gt;Creator&lt;/span&gt; &lt;span class="rhd-media-creator field__item"&gt;Maarten Vandeperre&lt;/span&gt; &lt;/span&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: The microservices outline of our preferred platform architecture.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Now that we have this outline, let's discuss how to implement it.&lt;/p&gt; &lt;h2&gt;AWS single cloud vendor&lt;/h2&gt; &lt;p&gt;Within company XYZ, developers played with AWS in the past. The management and architects supported the choice for AWS, so the development team started the design of the application platform on AWS cloud. The list of requirements to design their cloud infrastructure is as follows:&lt;/p&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;The requirement of the person microservice is that it should run on a SQL database. Within AWS, there are various options, but the development team chooses AWS Aurora.&lt;/li&gt; &lt;li aria-level="1"&gt;The requirement of the movie microservice is that it should run on a NoSQL database. AWS only offers DynamoDB off-the-shelf, so they choose DynamoDB.&lt;/li&gt; &lt;li aria-level="1"&gt;The movie-tracking microservice has the same requirements as the movie service; hence they choose DynamoDB.&lt;/li&gt; &lt;li aria-level="1"&gt;The requirement of the movie recommendation service is that it should run on a graph database. Since AWS only offers Neptune off-the-shelf (at the time of writing), they choose Neptune. If they need machine learning models, the development team can opt for AWS Athena or a machine learning model running on the graph database.&lt;/li&gt; &lt;li aria-level="1"&gt;The development team thinks that &lt;a href="https://developers.redhat.com/products/red-hat-openshift-service-on-aws/overview"&gt;Red Hat OpenShift on AWS (ROSA)&lt;/a&gt; is too expensive, so they choose the DIY solution provided by EKS or ECS (both &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; implementations of AWS), not thinking or knowing about the risks going along with this decision.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Now the development team has designed their cloud infrastructure for the cloud application platform (Figure 2).&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/step_2_general_design.jpeg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/step_2_general_design.jpeg?itok=zVVC7G-P" width="600" height="195" alt="An illustration of the design of the cloud architecture for the application platform." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;span class="field field--name-field-creator field--type-string field--label-inline field__items"&gt; &lt;span class="field__label"&gt;Creator&lt;/span&gt; &lt;span class="rhd-media-creator field__item"&gt;Maarten Vandeperre&lt;/span&gt; &lt;/span&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: The design of the cloud architecture for the application platform.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;In the next section, they will get back to the management team and the architects.&lt;/p&gt; &lt;h2&gt;The evaluation of dependencies&lt;/h2&gt; &lt;p&gt;In this section, we’ll look at the AWS services as if they were code dependencies. Instead of libraries referenced from the code (see our &lt;a href="https://developers.redhat.com/articles/2023/04/17/my-advice-building-maintainable-clean-architecture"&gt;previous article&lt;/a&gt;), these dependencies will be cloud services referenced from the microservices. If we refer to clean architecture, the four microservices are the core-layer (i.e., the business logic that should stand the test of time) and the AWS services are the dependencies that should be easy to replace. We should not tightly couple (combine) with any specific AWS service (as interface layer, &lt;a href="https://developers.redhat.com/articles/2022/03/14/choose-best-camel-your-integration-ride-part-1"&gt;Camel&lt;/a&gt; can be used, but more on that in future articles). There is one exception. EKS or ECS is the hosting infrastructure and can be seen as the programming language within clean architecture.&lt;/p&gt; &lt;p&gt;The management team and the architects looked at the design of the application platform’s cloud architecture and had the following recommendations (Figure 3):&lt;/p&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;&lt;strong&gt;Usage of AWS Aurora:&lt;/strong&gt; That’s fine. It’s recommended by AWS. It’s a stable solution. This choice is accepted (acceptance rate: green).&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Usage of DynamoDB&lt;/strong&gt;: This choice is not well received. The reason is that they bought or installed an on-premise bare-metal MongoDB cluster last year. In order to have some ROI, the management team and the architects prefer to use this cluster. If there is no other choice, DynamoDB can be accepted (acceptance rate: orange).&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Usage of Neptune:&lt;/strong&gt; This is a no-go. Although it’s provided off-the-shelf by AWS, it’s not the best graph database on the market (at the time of writing). The management team and the architects would prefer Neo4J or TigerGraph (acceptance rate: red).&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Usage of EKS or ECS:&lt;/strong&gt; Accepted by the management team and the architects, but this discussion is only won on the short-term pricing argument. They may have thought that OpenShift on AWS is too expensive, but they forgot the risks and the hidden costs that go along with a DIY solution.&lt;/li&gt; &lt;/ol&gt;&lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/step_3_evaluation.jpeg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/step_3_evaluation.jpeg?itok=ZgMY1Ge9" width="600" height="195" alt="An illustration of the evaluation of the dependencies." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;span class="field field--name-field-creator field--type-string field--label-inline field__items"&gt; &lt;span class="field__label"&gt;Creator&lt;/span&gt; &lt;span class="rhd-media-creator field__item"&gt;Maarten Vandeperre&lt;/span&gt; &lt;/span&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 3: The evaluation of the dependencies.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Because not everything was accepted, the development team must go back to the drawing board.&lt;/p&gt; &lt;h2&gt;Preferred dependencies&lt;/h2&gt; &lt;p&gt;The development team, good listeners as they are, take the feedback from the management team and architects into account and start adapting their architecture. Their preferred dependencies are as follows (Figure 4):&lt;/p&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;AWS Aurora was accepted. So AWS Aurora stays.&lt;/li&gt; &lt;li aria-level="1"&gt;Management was not too happy with the lack of ROI on their investment in the bare-metal MongoDB cluster. If they don’t want to have repercussions on future requested investments, it’s maybe a good idea to reuse that cluster, which is what they’ll do. AWS DynamoDB will be replaced by the on-premise bare-metal MongoDB cluster.&lt;/li&gt; &lt;li aria-level="1"&gt;Neptune was a no-go. The development team invests some time in reviewing graph databases. The winner in this exercise is Neo4J, off-the-shelf, offered by Google Cloud. AWS Neptune will be replaced by Google Cloud Neo4J.&lt;/li&gt; &lt;/ol&gt;&lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/step_4_add_preferred_dependencies.jpeg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/step_4_add_preferred_dependencies.jpeg?itok=qpsizAp5" width="600" height="189" alt="An illustration adding the preferred dependencies to the architecture." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;span class="field field--name-field-creator field--type-string field--label-inline field__items"&gt; &lt;span class="field__label"&gt;Creator&lt;/span&gt; &lt;span class="rhd-media-creator field__item"&gt;Maarten Vandeperre&lt;/span&gt; &lt;/span&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 4: Adding the recommended or preferred dependencies to the architecture.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;All of these changes should go relatively easy because the development team follows the principles of clean architecture. But it does not go easy. EKS or ECS has issues connecting to our on-premise MongoDB cluster and Google Cloud Neo4J (unless they spend quite some time and effort in fixing the network setup, which would even open the door for security flaws, as the development team is less trained in networking and operations).&lt;/p&gt; &lt;p&gt;The development team does not know how to fix the cloud (i.e., core layer) issue regarding the dependencies and asks the architects for input. This will be covered in the next section.&lt;/p&gt; &lt;p&gt;There is an analogy that can be made with &lt;a href="http://developers.redhat.com/topics/java"&gt;Java&lt;/a&gt; and &lt;a href="https://developers.redhat.com/topics/python"&gt;Python&lt;/a&gt;. Imagine that person service is a Java service and that the on-premise MongoDB is a Python library. If the programming language (like EKS or ECS) is Java, you won’t be able to access the Python libraries from within the person service. If you change the programming language to JVM and then to GraalVM, it would allow Java code to access Python scripts. It then would allow that the movie and movie tracking service are Python scripts (i.e., allow using these libraries) and that they can be called from within a Java service. Changing the programming language from Java to GraalVM, opened the options to a broader spectrum of third-party libraries.&lt;/p&gt; &lt;h2&gt;Hybrid cloud and multicloud solutions to the rescue&lt;/h2&gt; &lt;p&gt;The development team consults the architects with the issue: “We have isolated our dependencies (i.e., cloud services), but have issues with organizing our core layer (i.e., the third-party independent business logic, the microservices).” The architects look to see where the issue originated.&lt;/p&gt; &lt;p&gt;Clean architecture is about keeping your options open. The development team did this, but they narrowed the options too much by limiting their programming language (i.e., the microservice hosting platform) to AWS only. What they really need to make full use of the options available in the cloud and on-premise, is a hybrid cloud and multicloud. With a hybrid cloud, we mean the combination of a part of the cloud located at a vendor and a part of the cloud located on-premise. With a multicloud, we mean that the cloud is located over multiple vendors.&lt;em&gt; &lt;/em&gt;When hybrid cloud and multicloud solutions are enabled as programming language, the development team will be able to use the preferred dependencies: AWS Aurora, on-premise MongoDB, and Google Cloud Neo4J.&lt;/p&gt; &lt;p&gt;This architecture will withstand the test of time as well. Whenever a new SaaS solution becomes available or a new cloud emerges, or new tooling is needed, it will be easy to plug it in the designed cloud architecture (Figure 5). This results in a more resilient platform that requires less maintenance and that fairly easily allows for future innovation.&lt;strong&gt; &lt;/strong&gt;&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/step_5_hybrid_and_multi_cloud.jpeg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/step_5_hybrid_and_multi_cloud.jpeg?itok=YSx4igPs" width="600" height="201" alt="An illustration of the hybrid cloud and multicloud options." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;span class="field field--name-field-creator field--type-string field--label-inline field__items"&gt; &lt;span class="field__label"&gt;Creator&lt;/span&gt; &lt;span class="rhd-media-creator field__item"&gt;Maarten Vandeperre&lt;/span&gt; &lt;/span&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 5: Hybrid cloud and multicloud.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;But how can they implement a hybrid cloud and multicloud solution?&lt;/p&gt; &lt;h2&gt;How to set up hybrid cloud and multicloud solutions&lt;/h2&gt; &lt;p&gt;How do you set up hybrid cloud or multicloud solutions? &lt;a href="www.redhat.com/en/resources/openshift-container-platform-datasheet"&gt;Red Hat OpenShift Container Platform&lt;/a&gt; is the answer. It is a &lt;a href="https://developers.redhat.com/topics/containers"&gt;container&lt;/a&gt; platform that has the ability to easily start building hybrid cloud and/or multicloud solutions.&lt;/p&gt; &lt;p&gt;Although we used OpenShift as a solution for the issues that come along with EKS, OpenShift is more than just a Kubernetes installation or implementation. OpenShift Container Platform is a full application container platform. Check with the OpenShift specialists about how to bring the hybrid cloud and multi-cloud service to your company. Get started with a &lt;a href="https://developers.redhat.com/products/red-hat-openshift-service-on-aws/overview"&gt;Red Hat OpenShift Service on AWS (ROSA) trial&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/04/17/my-advice-transitioning-clean-architecture-platform" title="My advice for transitioning to a clean architecture platform"&gt;My advice for transitioning to a clean architecture platform&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Maarten Vandeperre, Kevin Dubois</dc:creator><dc:date>2023-04-17T07:01:00Z</dc:date></entry><entry><title>My advice for building maintainable, clean architecture</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/04/17/my-advice-building-maintainable-clean-architecture" /><author><name>Maarten Vandeperre, Kevin Dubois</name></author><id>cd4e3633-e78e-4cbd-b4b1-669cf87598f3</id><updated>2023-04-17T07:00:00Z</updated><published>2023-04-17T07:00:00Z</published><summary type="html">&lt;p&gt;To say that &lt;a href="https://developers.redhat.com/topics/devops/"&gt;DevOps&lt;/a&gt; is an illusion is a controversial statement to start this article. What I mean is that I often see DevOps passing by, but I have the feeling that they forgot the “and.” Development and operations are often two separated silos, not looking at each other, not looking at each other’s principles, even in cloud development. One of the best examples of looking for best practices in other silos is (in my opinion) agile software development, which originated from the Japanese car manufacturer, Toyota.&lt;/p&gt; &lt;p&gt;As hybrid and/or multi-cloud is often positioned from an infrastructure point of view, I believe that it can bring added value to tell the story about it, seeing through “application development glasses" instead of “infrastructure glasses." Hence, we wrote this article.&lt;/p&gt; &lt;p&gt;This is part one of two articles in a series about clean architecture. Part two covers &lt;a href="https://developers.redhat.com/articles/2023/04/17/my-advice-transitioning-clean-architecture-platform"&gt;transitioning to a clean architecture platform&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Knowing versus understanding&lt;/h2&gt; &lt;p&gt;Everybody knows mathematics, but not everybody understands integrals or knows how to apply volume calculations. Everybody knows that the surface of a triangle is ((b x h) / 2), but not everybody knows how to come to this formula. Some developers know the concept of clean architecture but don’t understand the internal details or principles enough to apply it to other domains (e.g., cloud infrastructure and cloud platform setup).&lt;/p&gt; &lt;p&gt;We often look at &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; with infrastructure glasses, but development-oriented people care less about security, ease to set up the cluster(s). Next to that, infrastructure-oriented people are less interested in application development best practices, while there can be or should be a synergy between the two worlds.&lt;/p&gt; &lt;h3&gt;How to handle data&lt;/h3&gt; &lt;p&gt;Consider the concepts of DRY vs. WRYMSIU (i.e., while repeating yourself, make sure it’s useful). Don’t repeat yourself. Personally, I think this statement is outdated and should be replaced with WRYMSIU (I apologize, I’m not the best inventor of acronyms). This means that you can repeat yourself (e.g., data), but only if the duplication of data brings added value (like we will see later).&lt;/p&gt; &lt;p&gt;An example of this is an analytics engine that runs in another environment than where your result-showing application is living. If application performance is a priority, then it can bring added value to copy the result-data from the environment of the analytics engine to the application environment. Nowadays, storage is not that expensive anymore, which leads to my opinion that DRY is outdated.&lt;/p&gt; &lt;h3&gt;Java application setup&lt;/h3&gt; &lt;p&gt;There are a lot of options in dependencies and languages, but in order to set up a project or application, you need to work in the scope or context of a programming language. This is the only choice that you should be or will be tied to.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;Dependencies: &lt;/strong&gt;Libraries or frameworks that are provided by third parties and that offer some functionality (e.g., logging, connection to Oracle, MongoDB, MySQL, databases, framework to expose REST/GraphQL endpoints). They are linked to your code base and can then be included within your source code (see Image 1).&lt;/li&gt; &lt;li&gt;&lt;strong&gt;SOA&lt;/strong&gt;: Service-oriented architecture. Controller (i.e., entry point), service layer (i.e., business logic), repository layer (i.e., database layer and persistence layer). Issues with SOA include the concept of service is error-prone (i.e., updating the code base to introduce workflow x can break workflow y). In this analogy, serverless function, &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; Jobs should be preferred over real applications, but out of scope for this presentation.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Focus lies on dependencies from now on, with the choice for &lt;a href="http://developers.redhat.com/topics/java"&gt;Java&lt;/a&gt; as programming language.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 1: Pollution of data classes (i.e., domain entities)&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;The issue with this way of coding is the database layer is directly intertwined with the domain entity (Figure 1). This results in that you have to know which type of database you’ll be using at the time of writing your data classes, and that whenever you would like to change your database technology, you’ll need to change the application core (i.e., business logic and application behavior).&lt;/p&gt; &lt;p&gt;A third issue with such code is the fact that data validation is handled by the library, based upon annotations. When you would try a new database technology, and you forget that validation should be rewritten now, the entire data validation will be compromised. Quite a lot of risks to just try out or change a library or database layer.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/code_annotations.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/code_annotations.png?itok=eYRl5AEI" width="450" height="587" alt="Import of dependencies and hard link with database layer and annotations in code." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;span class="field field--name-field-license field--type-entity-reference field--label-inline field__items"&gt; &lt;span class="field__label"&gt;License&lt;/span&gt; &lt;span class="rhd-media-licence field__item"&gt; under &lt;a href="https://www.apache.org/licenses/LICENSE-2.0" title="Apache 2.0"&gt;Apache 2.0&lt;/a&gt;. &lt;/span&gt; &lt;/span&gt;&lt;span class="field field--name-field-source-url field--type-string field--label-hidden field__items"&gt; https://github.com/spring-projects/spring-petclinic&lt;/span&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: Import of dependencies and hard link with database layer and annotations in code.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Example 2: Dependencies in the core (i.e., service) layer&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Source: &lt;a href="https://github.com/kozmer/log4j-shell-poc/blob/main/vulnerable-application/src/main/java/com/example/log4shell/LoginServlet.java"&gt;Log4J shell POC&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Issue with this way of coding: This simple business logic (Figure 2) is tightly coupled to the Apache log4j library. Whenever you now would like to use another logging framework/library, you’ll have to refactor/touch a lot of classes, and you’ll have to touch the business logic layer. Hence, you’ll have a risk of introducing bugs in your application’s behavior, just by changing a library. This should never be the case, and this is something what implementing clean architecture (properly) would prevent.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/code_logger.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/code_logger.png?itok=aomva3sv" width="600" height="510" alt="Java code with library dependency to support logging functionality using third-party dependencies in code." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;span class="field field--name-field-license field--type-entity-reference field--label-inline field__items"&gt; &lt;span class="field__label"&gt;License&lt;/span&gt; &lt;span class="rhd-media-licence field__item"&gt; under &lt;a href="https://www.apache.org/licenses/LICENSE-2.0" title="Apache 2.0"&gt;Apache 2.0&lt;/a&gt;. &lt;/span&gt; &lt;/span&gt;&lt;span class="field field--name-field-source-url field--type-string field--label-hidden field__items"&gt; https://github.com/spring-projects/spring-petclinic&lt;/span&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: Java code with library dependency to support logging functionality using third-party dependencies in code.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Both examples showed that depending on third-party libraries in your core/service/business logic layer can result in the following:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;&lt;strong&gt;Higher maintenance costs and cycles&lt;/strong&gt; (i.e., hard to keep dependencies up-to-date).&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Higher risk&lt;/strong&gt; when changing/upgrading dependencies.&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Less innovation&lt;/strong&gt;: It takes some time to change dependencies, and it comes with risks. Not too much enthusiasm to play around with new technologies or dependencies.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;This is something that implementing clean architecture properly would prevent. Clean architecture can still cause bugs during refactoring, but business logic should not break.&lt;/p&gt; &lt;h2&gt;What is clean architecture?&lt;/h2&gt; &lt;p&gt;One of the main principles of clean architecture is nothing more than keeping your options open by changing, adding, or removing dependencies as often as you want. We offer two analogies to illustrate this point.&lt;/p&gt; &lt;h3&gt;Real world analogies&lt;/h3&gt; &lt;p&gt;If you’re in the lead of a football team, you better not offer long term contracts to a new coach: (maybe this is an exaggeration) because in 90% of the cases, a coach doesn’t last for more than two years. Offering short term contracts, will allow the team to change trainers as often as we think is needed to achieve good results.&lt;/p&gt; &lt;p&gt;As a business analogy, companies that do not focus on software development (e.g., companies with a focus towards biochemistry) often rely on consultancy companies. Again, to keep options open. When they need more software developers, want to change software developers (e.g., mismatch with the atmosphere within the team) or just want to decrease the amount of developers (e.g., wrapping up of a project), then they are more flexible to do so when dealing with consultants than when they’d be dealing with internal employees.&lt;/p&gt; &lt;h3&gt;Technical explanation of clean architecture&lt;/h3&gt; &lt;p&gt;A good demo project can be found on &lt;a href="https://github.com/mattia-battiston/clean-architecture-example"&gt;GitHub by Mattia Battiston&lt;/a&gt;. I often start with this project to do my talks.&lt;/p&gt; &lt;p&gt;Clean architecture is about moving all your infrastructure and dependencies to the outer layer of your code base, leaving the business logic (domain entities and use cases, but these concepts are out of scope for this document/presentation) in the core (Figures 3 and 4). This has as an added value that it’s fairly cheap to change infrastructure, dependencies, or libraries as they are in the outer layer. Moving from &lt;a href="https://developers.redhat.com/topics/spring-boot/"&gt;Spring Boot&lt;/a&gt; to &lt;a href="https://developers.redhat.com/node/219015"&gt;Quarkus&lt;/a&gt;, replacing Oracle with MySQL, ... will be easier to do. When trying something new is fairly cheap, then development teams can work around proof-of-concepts regarding modernizing their code base/application platform driving innovation&lt;strong&gt; &lt;/strong&gt;(i.e., goes hand-in-hand with the values of Red Hat).&lt;/p&gt; &lt;p&gt;Last but not least, making it easy to change dependencies results in easier dependency upgrades without the risk of breaking the business logic. Hence, the core-layer (i.e., the business logic) is relatively easy to maintain and should be able to live for a longer period of time&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Infrastructure and dependencies often go hand-in-hand as every infrastructure component is managed by a third-party library. This is the case for REST/GraphQL APIs, databases, jobs, and file system access and network calls (although basic functionality to do so, is embedded in Java since Java 11).&lt;br /&gt;&lt;br /&gt; As it’s not the focus of this article to do a deep dive about clean architecture, we’ll go for now with the concept of clean architecture is abstracting away business logic, the core of your business, from it’s (external, infrastructural) dependencies to avoid the marriage between infrastructure and dependencies&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;As a side note (but beyond the scope of this article), going from SOA to use cases, makes you let go of DRY (for a valid reason in my opinion).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/clean_architecture_hexagonal.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/clean_architecture_hexagonal.png?itok=CD8cYErC" width="600" height="450" alt="Clean Architecture - Hexagonal Visual" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;span class="field field--name-field-source-url field--type-string field--label-hidden field__items"&gt; https://github.com/mattia-battiston/clean-architecture-example&lt;/span&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 3: Clean architecture (V1) - Clean Architecture - Hexagonal Visual&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/clean_architecture_uncle_bob.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/clean_architecture_uncle_bob.png?itok=TU2pF9cx" width="600" height="450" alt="Clean Architecture - Uncle Bob's Visual" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;span class="field field--name-field-source-url field--type-string field--label-hidden field__items"&gt; https://github.com/mattia-battiston/clean-architecture-example&lt;/span&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 4: Clean architecture (V2) - Clean Architecture - Uncle Bob's Visual&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;h2&gt;Learn more about clean architecture&lt;/h2&gt; &lt;p&gt;In this article, I shared my opinions and advice about the benefits of building maintainable, clean architecture. If you want to learn more about clean architecture, feel free to reach out to me (but reserve some time because I’m passionate about it).&lt;/p&gt; &lt;p&gt;Be sure to check out the &lt;a href="https://developers.redhat.com/articles/2023/04/17/my-advice-transitioning-clean-architecture-platform"&gt;next article&lt;/a&gt; discussing the transition from functional &lt;a href="https://developers.redhat.com/topics/microservices/"&gt;microservices&lt;/a&gt; to a clean architecture platform. If you have any questions, please comment below. We welcome your feedback.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/04/17/my-advice-building-maintainable-clean-architecture" title="My advice for building maintainable, clean architecture"&gt;My advice for building maintainable, clean architecture&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Maarten Vandeperre, Kevin Dubois</dc:creator><dc:date>2023-04-17T07:00:00Z</dc:date></entry><entry><title type="html">Byteman 4.0.21 has been released</title><link rel="alternate" href="http://bytemanblog.blogspot.com/2023/04/byteman-4021-has-been-released.html" /><author><name>Andrew Dinn</name></author><id>http://bytemanblog.blogspot.com/2023/04/byteman-4021-has-been-released.html</id><updated>2023-04-14T10:55:00Z</updated><content type="html">  Byteman 4.0.21 is now available from the and from the . It is the latest update release for use on all JDK9+ runtimes up to and including JDK21.   Byteman 4.0.21 is a maintenance release which enables Byteman to be used with JDK21 releases. It also contains one  small bug fixes and a feature enhancement. More details are provided in the and the latest .</content><dc:creator>Andrew Dinn</dc:creator></entry></feed>
